{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Project\n",
    "\n",
    "This is an analysis of data that is available and described [here](http://www.primaryobjects.com/2016/06/22/identifying-the-gender-of-a-voice-using-machine-learning/) and [here](https://www.kaggle.com/primaryobjects/voicegender). \n",
    "\n",
    "### Read in data and examine structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3168, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "\n",
       "          kurt    sp.ent       sfm  ...    centroid   meanfun    minfun  \\\n",
       "0   274.402906  0.893369  0.491918  ...    0.059781  0.084279  0.015702   \n",
       "1   634.613855  0.892193  0.513724  ...    0.066009  0.107937  0.015826   \n",
       "2  1024.927705  0.846389  0.478905  ...    0.077316  0.098706  0.015656   \n",
       "3     4.177296  0.963322  0.727232  ...    0.151228  0.088965  0.017798   \n",
       "4     4.333713  0.971955  0.783568  ...    0.135120  0.106398  0.016931   \n",
       "\n",
       "     maxfun   meandom    mindom    maxdom   dfrange   modindx  label  \n",
       "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000   male  \n",
       "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632   male  \n",
       "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512   male  \n",
       "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119   male  \n",
       "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274   male  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "voice_data = pd.read_csv('voice.csv')\n",
    "\n",
    "print voice_data.shape\n",
    "voice_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into features and labels\n",
    "\n",
    "Notice that we use the `train_test_split` function *twice*: the first time is to separate a final, untouchable test set, and later, when training classifiers, we will use it a second is to split into test and validate sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['meanfreq', 'sd', 'median', 'Q25', 'Q75', 'IQR', 'skew', 'kurt', 'sp.ent', 'sfm', 'mode', 'centroid', 'meanfun', 'minfun', 'maxfun', 'meandom', 'mindom', 'maxdom', 'dfrange', 'modindx']\n"
     ]
    }
   ],
   "source": [
    "labels = voice_data['label']\n",
    "features = voice_data.drop('label', 1)\n",
    "\n",
    "\n",
    "print list(features.columns.values)\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "features_temp, features_test, labels_temp, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.1, random_state=42)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a classifier, fit it to some training data, and examine its accuracy via validation data.\n",
    "\n",
    "Notice that we use the `train_test_split` function *twice*: the first time is to separate a final, untouchable test set, and later, when training classifiers, we will use it a second is to split into test and validate sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: \t\t0.003 s\n",
      "[[378  56]\n",
      " [ 34 388]]\n",
      "accuracy score: \t0.894859813084\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "gnb = GaussianNB()\n",
    "dct = DecisionTreeClassifier(random_state=1337, max_depth=10)\n",
    "svc = SVC()\n",
    "\n",
    "clf = gnb\n",
    "    \n",
    "from sklearn.cross_validation import train_test_split\n",
    "features_train, features_val, labels_train, labels_val = \\\n",
    "    train_test_split(features_temp, labels_temp, test_size=0.3, random_state=42)\n",
    "\n",
    "from time import time\n",
    "\n",
    "#print len(features_train)\n",
    "#print len(labels_train)\n",
    "\n",
    "#print features_train[0]\n",
    "#print labels_train[0]\n",
    "\n",
    "# Train classifier on train features and train labels\n",
    "# Measure and print the time taken\n",
    "t0 = time()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "print \"training time:\", \"\\t\\t\", round(time()-t0, 3), \"s\"\n",
    "c\n",
    "pred = clf.predict(features_val)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print confusion_matrix(labels_val, pred, labels=[\"female\", \"male\"])\n",
    "\n",
    "# Report accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print \"accuracy score:\", \"\\t\", accuracy_score(labels_val, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance using Gaussian Naive Bayes on all features\n",
    "\n",
    "As can be seen above, a simple classifier performs much better than chance on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: \t\t0.027 s\n",
      "[[412  22]\n",
      " [ 17 405]]\n",
      "accuracy score: \t0.954439252336\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dct = DecisionTreeClassifier(random_state=1337, max_depth=10)\n",
    "\n",
    "clf = dct\n",
    "    \n",
    "from time import time\n",
    "\n",
    "t0 = time()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "print \"training time:\", \"\\t\\t\", round(time()-t0, 3), \"s\"\n",
    "\n",
    "pred = clf.predict(features_val)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print confusion_matrix(labels_val, pred, labels=[\"female\", \"male\"])\n",
    "\n",
    "# Report accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print \"accuracy score:\", \"\\t\", accuracy_score(labels_val, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance using a decision tree classifier on all features\n",
    "\n",
    "A decision tree with max depth of 10 does very well on the data. What's going on? Next we look at the best features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sd', 'Q25', 'IQR', 'sp.ent', 'sfm', 'centroid', 'meanfun']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sd</th>\n",
       "      <th>Q25</th>\n",
       "      <th>IQR</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sd       Q25       IQR    sp.ent       sfm  centroid   meanfun\n",
       "0  0.064241  0.015071  0.075122  0.893369  0.491918  0.059781  0.084279\n",
       "1  0.067310  0.019414  0.073252  0.892193  0.513724  0.066009  0.107937\n",
       "2  0.083829  0.008701  0.123207  0.846389  0.478905  0.077316  0.098706\n",
       "3  0.072111  0.096582  0.111374  0.963322  0.727232  0.151228  0.088965\n",
       "4  0.079146  0.078720  0.127325  0.971955  0.783568  0.135120  0.106398"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "kbest = 7\n",
    "\n",
    "selector = SelectKBest(k=kbest)\n",
    "selectedFeatures = selector.fit(features_train, labels_train)\n",
    "\n",
    "feature_names = [list(features.columns.values)[i] for i in selectedFeatures.get_support(indices=True)]\n",
    "\n",
    "print feature_names\n",
    "\n",
    "kbestlabels = voice_data[feature_names]\n",
    "\n",
    "kbestlabels.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### meanfun is the best feature\n",
    "\n",
    "Above we have selected the 7 best features. It turns out that 'mean fundamental frequency', which is the average lowest frequency (similar to the 'main note' a monophonic instrument plays) is the single feature that predicts the most variance in the male/female label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing a model using only the best feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: \t\t0.003 s\n",
      "[[403  31]\n",
      " [ 16 406]]\n",
      "accuracy score for meanfun: \t0.945093457944\n",
      "[[264 170]\n",
      " [133 289]]\n",
      "accuracy score for meanfreq: \t0.646028037383\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "clf=gnb\n",
    "features_train_best = features_train[['meanfun']]\n",
    "\n",
    "clf = clf.fit(features_train_best, labels_train)\n",
    "\n",
    "print \"training time:\", \"\\t\\t\", round(time()-t0, 3), \"s\"\n",
    "\n",
    "pred = clf.predict(features_val[['meanfun']])\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print confusion_matrix(labels_val, pred, labels=[\"female\", \"male\"])\n",
    "\n",
    "# Report accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print \"accuracy score for meanfun:\", \"\\t\", accuracy_score(labels_val, pred)\n",
    "\n",
    "features_train_freq = features_train[['meanfreq']]\n",
    "clf = gnb\n",
    "clf = clf.fit(features_train_freq, labels_train)\n",
    "pred = clf.predict(features_val[['meanfreq']])\n",
    "print confusion_matrix(labels_val, pred, labels=[\"female\", \"male\"])\n",
    "\n",
    "# Report accuracy\n",
    "\n",
    "print \"accuracy score for meanfreq:\", \"\\t\", accuracy_score(labels_val, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### meanfun is highly predictive\n",
    "\n",
    "As can be seen above, using a simple univariate Gaussian classifier with this single feature is highly successful. When we check the final performance using the held-out test data, we will revisit this.\n",
    "\n",
    "Notice that the `'meanfreq'` feature only provided a 64% classifier accuracy. This suggests that human voices are full of overtones that are less correlated with gender than the base frequency.\n",
    "\n",
    "### Tuning hyperparameters\n",
    "\n",
    "First we use lots of stratified shuffle splits to find optimal hyperparameters. It is important to note that we now use all of the data except the held-out test data for tuning hyperparameters. Because decision trees worked so well, we will use the Adaboost algorithm applied to decision trees. This is the default setting for the `AdaBoostClassifier` in `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: \t\t1403.966 s\n",
      "gs.best_params_\n",
      "{'n_estimators': 50, 'learning_rate': 0.5}\n",
      "\n",
      "gs.best_estimator_\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=0.5, n_estimators=50, random_state=None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn import grid_search\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "cv = StratifiedShuffleSplit(labels_temp, 100, random_state = 11)\n",
    "\n",
    "parameters_abc={'n_estimators':[1,2,3,5,6,7,8,9,10,20,30,40,50],\n",
    "    'learning_rate':[0.1,0.15,0.2,0.3,0.4,0.5,0.9,1]}\n",
    "\n",
    "gs = grid_search.GridSearchCV(abc,parameters_abc,cv = cv)\n",
    "gs.fit(features_temp, labels_temp)\n",
    "\n",
    "print \"training time:\", \"\\t\\t\", round(time()-t0, 3), \"s\"\n",
    "\n",
    "print \"gs.best_params_\"\n",
    "print gs.best_params_\n",
    "\n",
    "print \"\"\n",
    "print \"gs.best_estimator_\"\n",
    "print gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning is expensive\n",
    "\n",
    "It took about 23 minutes on my computer using the parameters above.\n",
    "\n",
    "### Tuning parameters\n",
    "\n",
    "Then, using the best hyperparameters, we train using 10-fold cross validation across all non-test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.97499999999999998)\n",
      "(1, 0.98499999999999999)\n",
      "(2, 0.95999999999999996)\n",
      "(3, 0.97499999999999998)\n",
      "(4, 0.98499999999999999)\n",
      "(5, 0.97989949748743721)\n",
      "(6, 0.97487437185929648)\n",
      "(7, 0.96482412060301503)\n",
      "(8, 0.97487437185929648)\n",
      "(9, 0.96984924623115576)\n",
      "Average performance:  0.974432160804\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abc = AdaBoostClassifier(learning_rate=0.5, n_estimators=50)\n",
    "\n",
    "clf = abc\n",
    "\n",
    "from sklearn import cross_validation\n",
    "#print len(features_temp)\n",
    "#print len(labels_temp)\n",
    "k_fold = cross_validation.KFold(len(features_train), 10)\n",
    "\n",
    "averagePerformance = 0.\n",
    "\n",
    "for k, (train, test) in enumerate(k_fold):\n",
    "    #print train\n",
    "    #print test\n",
    "    clf.fit(features_temp.iloc[train], labels_temp.iloc[train])\n",
    "    print(k, clf.score(features_temp.iloc[test], labels_temp.iloc[test]))\n",
    "    averagePerformance += clf.score(features_temp.iloc[test], labels_temp.iloc[test])\n",
    "\n",
    "print \"Average performance: \" , averagePerformance / 10\n",
    "finalABC = clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[147   5]\n",
      " [  1 164]]\n",
      "accuracy score for final adaboost classifier over all features: \t0.981072555205\n",
      "[[135  17]\n",
      " [ 13 152]]\n",
      "accuracy score for final gaussian naive bayes classifier over all features: \t0.905362776025\n",
      "[[145   7]\n",
      " [  4 161]]\n",
      "accuracy score for final gaussian naive bayes classifier for meanfun: \t0.965299684543\n"
     ]
    }
   ],
   "source": [
    "clf = finalABC\n",
    "pred = clf.predict(features_test)\n",
    "print confusion_matrix(labels_test, pred, labels=[\"female\", \"male\"])\n",
    "print \"accuracy score for final adaboost classifier over all features:\", \"\\t\", accuracy_score(labels_test, pred)\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf = clf.fit(features_temp, labels_temp)\n",
    "pred = clf.predict(features_test)\n",
    "print confusion_matrix(labels_test, pred, labels=[\"female\", \"male\"])\n",
    "print \"accuracy score for final gaussian naive bayes classifier over all features:\", \"\\t\", accuracy_score(labels_test, pred)\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf = clf.fit(features_temp[['meanfun']], labels_temp)\n",
    "pred = clf.predict(features_test[['meanfun']])\n",
    "print confusion_matrix(labels_test, pred, labels=[\"female\", \"male\"])\n",
    "cprint \"accuracy score for final gaussian naive bayes classifier for meanfun:\", \"\\t\", accuracy_score(labels_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Can only tuple-index with a MultiIndex",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-8c3fbb5b0970>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m# Generate a minibatch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;31m# Prepare a dictionary telling the session where to feed the minibatch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# The key of the dictionary is the placeholder node of the graph to be fed,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m_get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m_get_values_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Can only tuple-index with a MultiIndex'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# If key is contained, would have returned by now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Can only tuple-index with a MultiIndex"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 128\n",
    "num_labels = 2\n",
    "\n",
    "beta = 0.01\n",
    "\n",
    "input_size = features_temp.shape[1]\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "# Input data. For the training data, we use a placeholder that will be fed\n",
    "\n",
    "# at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, input_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(features_val.as_matrix().astype(np.float32))\n",
    "    tf_test_dataset = tf.constant(features_test.as_matrix().astype(np.float32))\n",
    "\n",
    "    # Variables.\n",
    "    weights = tf.Variable(\n",
    "        tf.truncated_normal([input_size, num_labels]))\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "    loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels) + \n",
    "            beta*tf.nn.l2_loss(weights))\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)\n",
    "    \n",
    "num_steps = 500\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (labels_train.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = features_train.as_matrix().astype(np.float32)[offset:(offset + batch_size), :]\n",
    "        batch_labels = labels_train[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "        print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "        print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "        print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "            valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
