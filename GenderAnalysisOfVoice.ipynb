{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Group Project\n",
    "\n",
    "This is an analysis of data that is available and described [here](http://www.primaryobjects.com/2016/06/22/identifying-the-gender-of-a-voice-using-machine-learning/) and [here](https://www.kaggle.com/primaryobjects/voicegender). \n",
    "\n",
    "### Read in data and examine structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3168, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "\n",
       "          kurt    sp.ent       sfm  ...    centroid   meanfun    minfun  \\\n",
       "0   274.402906  0.893369  0.491918  ...    0.059781  0.084279  0.015702   \n",
       "1   634.613855  0.892193  0.513724  ...    0.066009  0.107937  0.015826   \n",
       "2  1024.927705  0.846389  0.478905  ...    0.077316  0.098706  0.015656   \n",
       "3     4.177296  0.963322  0.727232  ...    0.151228  0.088965  0.017798   \n",
       "4     4.333713  0.971955  0.783568  ...    0.135120  0.106398  0.016931   \n",
       "\n",
       "     maxfun   meandom    mindom    maxdom   dfrange   modindx  label  \n",
       "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000   male  \n",
       "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632   male  \n",
       "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512   male  \n",
       "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119   male  \n",
       "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274   male  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "voice_data = pd.read_csv('voice.csv')\n",
    "\n",
    "print voice_data.shape\n",
    "voice_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into features and labels\n",
    "\n",
    "Notice that we use the `train_test_split` function *twice*: the first time is to separate a final, untouchable test set, and later, when training classifiers, we will use it a second is to split into test and validate sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['meanfreq', 'sd', 'median', 'Q25', 'Q75', 'IQR', 'skew', 'kurt', 'sp.ent', 'sfm', 'mode', 'centroid', 'meanfun', 'minfun', 'maxfun', 'meandom', 'mindom', 'maxdom', 'dfrange', 'modindx']\n"
     ]
    }
   ],
   "source": [
    "labels = voice_data['label']\n",
    "features = voice_data.drop('label', 1)\n",
    "\n",
    "\n",
    "print list(features.columns.values)\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "features_temp, features_test, labels_temp, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.1, random_state=42)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a classifier, fit it to some training data, and examine its accuracy via validation data.\n",
    "\n",
    "Notice that we use the `train_test_split` function *twice*: the first time is to separate a final, untouchable test set, and later, when training classifiers, we will use it a second is to split into test and validate sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: \t\t0.024 s\n",
      "[[412  22]\n",
      " [ 17 405]]\n",
      "accuracy score: \t0.954439252336\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "gnb = GaussianNB()\n",
    "dct = DecisionTreeClassifier(random_state=1337)\n",
    "\n",
    "clf = dct\n",
    "    \n",
    "from sklearn.cross_validation import train_test_split\n",
    "features_train, features_val, labels_train, labels_val = \\\n",
    "    train_test_split(features_temp, labels_temp, test_size=0.3, random_state=42)\n",
    "\n",
    "from time import time\n",
    "\n",
    "#print len(features_train)\n",
    "#print len(labels_train)\n",
    "\n",
    "#print features_train[0]\n",
    "#print labels_train[0]\n",
    "\n",
    "# Train classifier on train features and train labels\n",
    "# Measure and print the time taken\n",
    "t0 = time()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "print \"training time:\", \"\\t\\t\", round(time()-t0, 3), \"s\"\n",
    "\n",
    "pred = clf.predict(features_val)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print confusion_matrix(labels_val, pred, labels=[\"female\", \"male\"])\n",
    "\n",
    "# Report accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print \"accuracy score:\", \"\\t\", accuracy_score(labels_val, pred)\n",
    "\n",
    "# Report precision\n",
    "#from sklearn.metrics import precision_score\n",
    "#print \"precision score:\", \"\\t\", precision_score(labels_val, pred)\n",
    "\n",
    "# Report recall\n",
    "#from sklearn.metrics import recall_score\n",
    "#print \"recall score:\", \"\\t\\t\", recall_score(labels_val, pred)\n",
    "\n",
    "\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# target_names = [\"Not POI\", \"POI\"]\n",
    "# print \"Classification Report:\"\n",
    "# print classification_report(y_true=labels_test, y_pred=pred, target_names=target_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sd', 'Q25', 'IQR', 'sp.ent', 'sfm', 'centroid', 'meanfun']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sd</th>\n",
       "      <th>Q25</th>\n",
       "      <th>IQR</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sd       Q25       IQR    sp.ent       sfm  centroid   meanfun\n",
       "0  0.064241  0.015071  0.075122  0.893369  0.491918  0.059781  0.084279\n",
       "1  0.067310  0.019414  0.073252  0.892193  0.513724  0.066009  0.107937\n",
       "2  0.083829  0.008701  0.123207  0.846389  0.478905  0.077316  0.098706\n",
       "3  0.072111  0.096582  0.111374  0.963322  0.727232  0.151228  0.088965\n",
       "4  0.079146  0.078720  0.127325  0.971955  0.783568  0.135120  0.106398"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "kbest = 7\n",
    "\n",
    "selector = SelectKBest(k=kbest)\n",
    "selectedFeatures = selector.fit(features_train, labels_train)\n",
    "\n",
    "feature_names = [list(features.columns.values)[i] for i in selectedFeatures.get_support(indices=True)]\n",
    "\n",
    "print feature_names\n",
    "\n",
    "kbestlabels = voice_data[feature_names]\n",
    "\n",
    "kbestlabels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: \t\t0.004 s\n",
      "[[398  36]\n",
      " [ 18 404]]\n",
      "accuracy score: \t0.93691588785\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "clf=gnb\n",
    "features_train_best = features_train[['meanfun', 'meanfreq', 'Q25', 'Q75', 'median']]\n",
    "\n",
    "clf = clf.fit(features_train_best, labels_train)\n",
    "\n",
    "print \"training time:\", \"\\t\\t\", round(time()-t0, 3), \"s\"\n",
    "\n",
    "pred = clf.predict(features_val[['meanfun', 'meanfreq', 'Q25', 'Q75', 'median']])\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print confusion_matrix(labels_val, pred, labels=[\"female\", \"male\"])\n",
    "\n",
    "# Report accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print \"accuracy score:\", \"\\t\", accuracy_score(labels_val, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Gaussian Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage Correct via ttest:  0.92025\n"
     ]
    }
   ],
   "source": [
    "from pylab import *\n",
    "import scipy.stats\n",
    "n = 100000\n",
    "\n",
    "# A distribution\n",
    "x1=array([randn(n)+1 , randn(n)+1])\n",
    "y1=zeros(n)\n",
    "\n",
    "\n",
    "# B distribution\n",
    "x2=array([randn(n)+3 , randn(n)+3]) \n",
    "y2=zeros(n)+1\n",
    "x = hstack((x1,x2)).T\n",
    "y = hstack((y1,y2))\n",
    "\n",
    "def getPredictionsKnowingFunctions(x):\n",
    "    preds = zeros(n*2)\n",
    "    A = scipy.stats.norm(1, 1)\n",
    "    B = scipy.stats.norm(3, 1)\n",
    "    i = 0\n",
    "    for ar in x:\n",
    "        probA = A.pdf(ar[0]) * A.pdf(ar[1])\n",
    "        probB = B.pdf(ar[0]) * B.pdf(ar[1])\n",
    "        if probA > probB:\n",
    "            preds[i] = 0\n",
    "        else:\n",
    "            preds[i] = 1\n",
    "        i+=1\n",
    "    return preds\n",
    "\n",
    "preds = getPredictionsKnowingFunctions(x)        \n",
    "\n",
    "numErrors = sum(abs(y-preds))\n",
    "print \"Percentage Correct via ttest: \" , (n*2 - numErrors) / (n*2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does a Gaussian Naive Bayes classifier do on this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: \t\t0.027 s\n",
      "[[24768  2203]\n",
      " [ 2173 24856]]\n",
      "accuracy score: \t0.918962962963\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "features_temp, features_test, labels_temp, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.1, random_state=42)\n",
    "    \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "gnb = GaussianNB()\n",
    "dct = DecisionTreeClassifier(random_state=1337)\n",
    "\n",
    "clf = gnb\n",
    "\n",
    "features_temp, features_test, labels_temp, labels_test = \\\n",
    "    train_test_split(x, y, test_size=0.1, random_state=42)\n",
    "    \n",
    "from sklearn.cross_validation import train_test_split\n",
    "features_train, features_val, labels_train, labels_val = \\\n",
    "    train_test_split(features_temp, labels_temp, test_size=0.3, random_state=42)\n",
    "\n",
    "from time import time\n",
    "\n",
    "#print len(features_train)\n",
    "#print len(labels_train)\n",
    "\n",
    "#print features_train[0]\n",
    "#print labels_train[0]\n",
    "\n",
    "# Train classifier on train features and train labels\n",
    "# Measure and print the time taken\n",
    "t0 = time()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "print \"training time:\", \"\\t\\t\", round(time()-t0, 3), \"s\"\n",
    "\n",
    "pred = clf.predict(features_val)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print confusion_matrix(labels_val, pred)\n",
    "\n",
    "# Report accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print \"accuracy score:\", \"\\t\", accuracy_score(labels_val, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like Gaussian Naive Bayes does so well compared to the optimal classifier that it makes the assumption of each feature representing a normal distribution with different mean/variance for each class (feature label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-156-1dbb3ac30844>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-156-1dbb3ac30844>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    def probDensSquareNorm(y)\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# What is the probability density function of the square of the normal distribution function squared at 2?\n",
    "x = 2\n",
    "def probDensSquareNorm(y)\n",
    "    return exp(-(x-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage Correct via ttest:  0.840295\n"
     ]
    }
   ],
   "source": [
    "from pylab import *\n",
    "import scipy.stats\n",
    "n = 100000\n",
    "\n",
    "# A distribution\n",
    "x1=array([randn(n)+1])\n",
    "y1=zeros(n)\n",
    "\n",
    "\n",
    "# B distribution\n",
    "x2=array([randn(n)+3]) \n",
    "y2=zeros(n)+1\n",
    "x = hstack((x1,x2)).T\n",
    "y = hstack((y1,y2))\n",
    "\n",
    "def getPredictionsKnowingFunctions(x):\n",
    "    preds = zeros(n*2)\n",
    "    A = scipy.stats.norm(1, 1)\n",
    "    B = scipy.stats.norm(3, 1)\n",
    "    i = 0\n",
    "    for ar in x:\n",
    "        probA = A.pdf(ar[0])\n",
    "        probB = B.pdf(ar[0])\n",
    "        if probA > probB:\n",
    "            preds[i] = 0\n",
    "        else:\n",
    "            preds[i] = 1\n",
    "        i+=1\n",
    "    return preds\n",
    "\n",
    "preds = getPredictionsKnowingFunctions(x)        \n",
    "\n",
    "numErrors = sum(abs(y-preds))\n",
    "print \"Percentage Correct via ttest: \" , (n*2 - numErrors) / (n*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage Correct via ttest:  0.9574\n"
     ]
    }
   ],
   "source": [
    "from pylab import *\n",
    "import scipy.stats\n",
    "n = 5000\n",
    "\n",
    "# A distribution\n",
    "x1=array([randn(n)+1 , randn(n)+1, randn(n)+1])\n",
    "y1=zeros(n)\n",
    "\n",
    "\n",
    "# B distribution\n",
    "x2=array([randn(n)+3 , randn(n)+3, randn(n)+3]) \n",
    "y2=zeros(n)+1\n",
    "x = hstack((x1,x2)).T\n",
    "y = hstack((y1,y2))\n",
    "\n",
    "def getPredictionsKnowingFunctions(x):\n",
    "    preds = zeros(n*2)\n",
    "    A = scipy.stats.norm(1, 1)\n",
    "    B = scipy.stats.norm(3, 1)\n",
    "    i = 0\n",
    "    for ar in x:\n",
    "        probA = A.pdf(ar[0]) * A.pdf(ar[1]) * A.pdf(ar[2]) \n",
    "        probB = B.pdf(ar[0]) * B.pdf(ar[1]) * B.pdf(ar[2])\n",
    "        if probA > probB:\n",
    "            preds[i] = 0\n",
    "        else:\n",
    "            preds[i] = 1\n",
    "        i+=1\n",
    "    return preds\n",
    "\n",
    "preds = getPredictionsKnowingFunctions(x)        \n",
    "\n",
    "numErrors = sum(abs(y-preds))\n",
    "print \"Percentage Correct via ttest: \" , (n*2 - numErrors) / (n*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
